## ğŸ§  Real-Time Tweet Sentiment Analysis Pipeline  
**Databricks | PySpark Structured Streaming | Delta Lake | Hugging Face | MLflow**

---

### ğŸš€ Overview  
Designed and deployed a **real-time streaming pipeline** to classify tweet sentiments at scale using **transformer-based NLP models** within **Apache Spark Structured Streaming**.  
The system processes millions of tweets with **low latency**, leveraging a **Delta Lake multi-layer architecture (Bronze â†’ Silver â†’ Gold)** and **MLflow** for tracking, model registry, and deployment.

> **Goal:** Bridge the gap between scalable data engineering and NLP by integrating distributed streaming with real-time model inference.

---

### ğŸ§© Architecture  
**Data Flow:**  
`Twitter Stream (JSON)` â†’ `Bronze (Raw)` â†’ `Silver (Cleaned)` â†’ `Gold (Predicted)`  

**Components:**  
- **Streaming Engine:** Apache Spark Structured Streaming  
- **Storage:** Delta Lake (ACID, checkpointing, schema evolution)  
- **Model:** Hugging Face `cardiffnlp/twitter-roberta-base-sentiment`  
- **Model Management:** MLflow (tracking, registry, serving)  
- **Infrastructure:** Databricks on AWS (S3 as source + Delta for persistence)  
- **Visualization:** Real-time sentiment dashboards built from Gold table  

---

### âš™ï¸ Pipeline Workflow  

1. **Ingestion â€“ Bronze Layer**  
   - Continuously reads tweet JSON streams from `s3a://voc-75-databricks-data/voc_volume/`  
   - Stores raw semi-structured data into Bronze Delta Table  

2. **Transformation â€“ Silver Layer**  
   - Extracts key fields: `full_text`, `timestamp`, `lang`, `user_id`  
   - Cleans nulls, deduplicates IDs, standardizes timestamps  

3. **Model Inference â€“ Gold Layer**  
   - Applies **Transformer-based sentiment classifier** via PySpark UDF  
   - Predicts sentiment labels: *positive, neutral, negative*  
   - Writes predictions to Gold Delta Table for downstream analytics  

---

### ğŸ§  Model & Tracking  
- **Model:** `cardiffnlp/twitter-roberta-base-sentiment` (Hugging Face)  
- **Integration:** MLflow logs metrics (Accuracy, F1, Latency) and version controls the model registry  
- **Deployment:** Registered model transitioned from *Staging* â†’ *Production* for continuous inference  

---

### ğŸ“Š Results & Observations  
- **Accuracy:** ~92% on validation set using pre-finetuned model  
- **Latency:** Stream batches processed every 60 seconds  
- **Robustness:** Delta checkpointing ensured fault-tolerant writes  
- **Insights:** Visualized sentiment trends aligned with major real-world events (e.g., spikes in negative sentiment during global crises)

---

### ğŸ§© Key Challenges & Solutions  
- **Transformer inference overhead** â†’ Batched processing + lightweight RoBERTa variant  
- **Stateful stream recovery** â†’ Delta checkpointing + idempotent writes  
- **Real-time model scaling** â†’ Asynchronous UDF + caching of embeddings  
- **MLflow registry sync** â†’ Automated transition scripts for model stage promotion  

---

ğŸ“ **Full Code:**  
[ğŸ‘‰ GitHub â€” Starter Streaming Tweet Sentiment (Spring 2024 Final Project)](https://github.com/leahnote01/dscc402/blob/main/final_project/Starter%20Streaming%20Tweet%20Sentiment%20-%20Spring%202024%20Final%20Project.ipynb)

---

ğŸ“˜ **Keywords:**  
`PySpark Structured Streaming` | `Delta Lake` | `Databricks` | `Transformer Models` | `MLflow` |  
`Real-Time Inference` | `Data Engineering` | `Hugging Face` | `MLOps` | `Sentiment Analysis`

